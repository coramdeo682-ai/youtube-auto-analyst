import os
import json
import time
from datetime import datetime, timedelta, timezone
from time import mktime
import feedparser
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import google.generativeai as genai
import pandas as pd

# ==========================================
# [í™•ì¸ìš©] ë‚´ê°€ ì‹¤í–‰ì‹œí‚¨ ì½”ë“œê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¬¸êµ¬
# ==========================================
print("\n" + "="*50)
print("ğŸš€ [ì‚¬ìš©ìë‹˜ í™•ì¸ìš©] ë‹¨ì¼ ì±„ë„ í…ŒìŠ¤íŠ¸ ë´‡ ê°€ë™!")
print("ğŸ¯ íƒ€ê²Ÿ ì±„ë„: ì˜¤ì§ 'ê¹€ì˜ìµì˜ ê²½ì œìŠ¤ì¿¨' í•˜ë‚˜ë§Œ ê²€ì‚¬í•©ë‹ˆë‹¤.")
print("="*50 + "\n")

# ==========================================
# [ì„¤ì •] í•œêµ­ ì‹œê°„ & ë‚ ì§œ í•„í„° & ì±„ë„
# ==========================================
KST = timezone(timedelta(hours=9))
FILTER_DAYS = 3

# â˜… ì—¬ê¸° ë”± í•˜ë‚˜ë§Œ ë‚¨ê²¼ìŠµë‹ˆë‹¤ â˜…
TARGET_CHANNELS = {
    "ê¹€ì˜ìµì˜ ê²½ì œìŠ¤ì¿¨" : "UCQIyAcoLsO3L0RMFQk7YMYA"
}

SYSTEM_PROMPT = """
[ë¶„ì„ ì§€ì¹¨]
1. 'key_arguments'ì™€ 'evidence'ëŠ” ì§ì„ ì´ë£¨ì–´ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ.
2. ìˆ˜ì¹˜(%, ê¸ˆì•¡, ë‚ ì§œ)ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ.
3. íˆ¬ìì ê´€ì ì—ì„œ ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•  ê²ƒ.

[JSON í¬ë§·]
{
  "video_id": "ì˜ìƒID",
  "url": "ì˜ìƒ ì „ì²´ URL",
  "title": "ì˜ìƒ ì œëª©",
  "channel_name": "ì±„ë„ëª…",
  "published_at": "ì—…ë¡œë“œ ë‚ ì§œ (YYYY-MM-DD)",
  "main_topic": "í•µì‹¬ ì£¼ì œ (1ë¬¸ì¥)",
  "key_arguments": ["í•µì‹¬ ì£¼ì¥ 1", "í•µì‹¬ ì£¼ì¥ 2", "í•µì‹¬ ì£¼ì¥ 3"],
  "evidence": ["ì£¼ì¥ 1ì— ëŒ€í•œ ê·¼ê±°(ìˆ˜ì¹˜/íŒ©íŠ¸)", "ì£¼ì¥ 2ì— ëŒ€í•œ ê·¼ê±°", "ì£¼ì¥ 3ì— ëŒ€í•œ ê·¼ê±°"],
  "implications": "ì´ ë‚´ìš©ì´ ì£¼ëŠ” ì‹œì‚¬ì  ë° íˆ¬ì ì¸ì‚¬ì´íŠ¸ (ìƒì„¸ ê¸°ìˆ )",
  "validity_check": "ë…¼ë¦¬ì  íƒ€ë‹¹ì„± ë° ë¹„íŒì  ê²€í† ",
  "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
  "tags": "í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3",
  "full_summary": "ì „ì²´ ë‚´ìš© ìƒì„¸ ìš”ì•½"
}
"""

def connect_google_sheet():
    try:
        json_creds = json.loads(os.environ['GCP_CREDENTIALS_JSON'])
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_dict(json_creds, scope)
        client = gspread.authorize(creds)
        sheet = client.open("Youtube_Data_Store").sheet1 
        return sheet
    except Exception as e:
        print(f"ğŸš¨ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def get_existing_video_ids(sheet):
    try:
        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        if df.empty or 'ì˜ìƒID' not in df.columns:
            return []
        return df['ì˜ìƒID'].astype(str).tolist()
    except:
        return []

def analyze_video(video_url):
    try:
        api_key = os.environ['GOOGLE_API_KEY']
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash') 
        full_prompt = f"{SYSTEM_PROMPT}\n\n[ë¶„ì„í•  ì˜ìƒ ë§í¬]: {video_url}"
        response = model.generate_content(full_prompt)
        text = response.text
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]
        return json.loads(text)
    except Exception as e:
        print(f"âŒ Gemini ë¶„ì„ ì‹¤íŒ¨ ({video_url}): {e}")
        return None

def is_recent_video(entry):
    try:
        published_time = entry.published_parsed
        video_date_utc = datetime.fromtimestamp(mktime(published_time), tz=timezone.utc)
        now_utc = datetime.now(timezone.utc)
        delta = now_utc - video_date_utc
        video_date_kst = video_date_utc.astimezone(KST).strftime("%Y-%m-%d")
        
        if delta.days <= FILTER_DAYS:
            return True, video_date_kst
        else:
            return False, video_date_kst
    except:
        return True, datetime.now(KST).strftime("%Y-%m-%d")

def run_bot():
    sheet = connect_google_sheet()
    if not sheet: return

    existing_ids = get_existing_video_ids(sheet)
    print(f"ğŸ“š ê¸°ì¡´ ë°ì´í„° {len(existing_ids)}ê°œ í™•ì¸ë¨")

    for channel_name, channel_id in TARGET_CHANNELS.items():
        rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
        feed = feedparser.parse(rss_url)
        
        print(f"ğŸ“¡ ìŠ¤ìº” ì¤‘: {channel_name} (ID: {channel_id})")
        print(f"   -> ìœ íŠœë¸Œì—ì„œ ê°€ì ¸ì˜¨ ìµœì‹  ì˜ìƒ ê°œìˆ˜: {len(feed.entries)}ê°œ")
        
        for entry in feed.entries:
            video_id = entry.yt_videoid
            video_url = entry.link
            video_title = entry.title
            
            if video_id in existing_ids:
                continue 

            is_recent, video_date = is_recent_video(entry)
            if not is_recent:
                continue

            print(f"   âœ¨ [ì‹ ê·œ ë°œê²¬] {video_title} ({video_date}) -> ë¶„ì„ ì‹œì‘")
            
            result = analyze_video(video_url)
            
            if result:
                key_args = "\n- ".join(result.get("key_arguments", []))
                if key_args: key_args = "- " + key_args
                evidence = "\n- ".join(result.get("evidence", []))
                if evidence: evidence = "- " + evidence

                row_data = [
                    datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S"),
                    result.get("published_at", video_date),
                    result.get("video_id", video_id),
                    result.get("title", video_title),
                    result.get("channel_name", channel_name),
                    result.get("main_topic", ""),
                    key_args,
                    evidence,
                    result.get("implications", ""),
                    result.get("validity_check", ""),
                    result.get("sentiment", ""),
                    result.get("full_summary", ""),
                    result.get("tags", ""),
                    result.get("url", video_url)
                ]
                
                sheet.append_row(row_data)
                print(f"   âœ… êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ!")
                existing_ids.append(video_id)
                time.sleep(5)

if __name__ == "__main__":
    run_bot()
