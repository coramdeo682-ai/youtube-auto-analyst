import os
import json
import time
from datetime import datetime, timedelta
from time import mktime
import feedparser
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import google.generativeai as genai
import pandas as pd

# ==========================================
# [ì„¤ì • 1] ë‚ ì§œ í•„í„° (ë©°ì¹  ì´ë‚´ ì˜ìƒë§Œ ê°€ì ¸ì˜¬ ê²ƒì¸ê°€?)
# ==========================================
FILTER_DAYS = 7  # ìµœê·¼ 7ì¼ ì´ë‚´ ì˜ìƒë§Œ ìˆ˜ì§‘ (ì˜¤ë˜ëœ ì˜ìƒ ë°©ì§€)

# ==========================================
# [ì„¤ì • 2] êµ¬ë…í•  ìœ íŠœë¸Œ ì±„ë„ ëª©ë¡ (ì±„ë„ ID ì…ë ¥)
# ==========================================
# â€» ì£¼ì˜: ì´ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆ˜ì •í–ˆë‹¤ë©´ ë°˜ë“œì‹œ GitHubì— Commit/Push í•´ì•¼ ì ìš©ë©ë‹ˆë‹¤.
TARGET_CHANNELS = {
    "ê¹€ì˜ìµì˜ ê²½ì œìŠ¤ì¿¨" : "UCQIyAcoLsO3L0RMFQk7YMYA",
    "ê²½ì œ ì½ì–´ì£¼ëŠ” ë‚¨ì(ê¹€ê´‘ì„TV)" : "UC3pfEoxaRDT6hvZZjpHu7Tg",
    "ë‚´ì¼ì€ íˆ¬ìì™• - ê¹€ë‹¨í…Œ" : "UCKTMvIu9a4VGSrpWy-8bUrQ",
    "ë°•ì¢…í›ˆì˜ ì§€ì‹í•œë°©" : "UCOB62fKRT7b73X7tRxMuN2g",
    "ì›”ê°€ì•„ì¬ì˜ ê³¼í•™ì  íˆ¬ì" : "UCpqD9_OJNtF6suPpi6mOQCQ",
    "ì „ì¸êµ¬ê²½ì œì—°êµ¬ì†Œ" : "UC3uzeWjN8v_ItMWhxILvuvQ",
    "ì¡´ë¦¬ì˜ ë¶€ìí•™êµ" : "UCXWOlSe2GHTev8QZhY_gMPg", 
    "íŠ¸ë˜ë¸”ì œì´(Travel J)ì£¼ì‹íˆ¬ìì™€ 10ë…„ ì„¸ê³„íƒë°©" : "UCM0iG9ePKMIuGxUFBObgK9A",  
    "í•  ìˆ˜ ìˆë‹¤! ì•Œê³  íˆ¬ì" : "UCSWPuzlD337Y6VBkyFPwT8g",
    "í™ì¶˜ìš±ì˜ ê²½ì œê°•ì˜ë…¸íŠ¸" : "UCmNbuxmvRVv9OcdAO0cpLnw"
}

# ==========================================
# [í”„ë¡¬í”„íŠ¸] Geminiì—ê²Œ ë³´ë‚¼ ë¶„ì„ ì§€ì¹¨
# ==========================================
SYSTEM_PROMPT = """
ì§€ê¸ˆë¶€í„° ë‚´ê°€ ìœ íŠœë¸Œ ë§í¬ë¥¼ ì£¼ë©´, í•´ë‹¹ ì˜ìƒì˜ ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ì•„ë˜ì˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´ ì¤˜. 
ë‹¤ë¥¸ ë§ì€ í•˜ì§€ ë§ê³  ì˜¤ì§ JSON ì½”ë“œë§Œ ì¶œë ¥í•´. (ì½”ë“œ ë¸”ë¡ ì•ˆì— ë„£ì–´ì„œ)

[ë¶„ì„ ì§€ì¹¨]
1. 'key_arguments'ì™€ 'evidence'ëŠ” ì§ì„ ì´ë£¨ì–´ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ.
2. ìˆ˜ì¹˜(%, ê¸ˆì•¡, ë‚ ì§œ)ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ.
3. íˆ¬ìì ê´€ì ì—ì„œ ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•  ê²ƒ.

[JSON í¬ë§·]
{
  "video_id": "ì˜ìƒID",
  "url": "ì˜ìƒ ì „ì²´ URL",
  "title": "ì˜ìƒ ì œëª©",
  "channel_name": "ì±„ë„ëª…",
  "published_at": "ì—…ë¡œë“œ ë‚ ì§œ (YYYY-MM-DD)",
  "main_topic": "í•µì‹¬ ì£¼ì œ (1ë¬¸ì¥)",
  "key_arguments": ["í•µì‹¬ ì£¼ì¥ 1", "í•µì‹¬ ì£¼ì¥ 2", "í•µì‹¬ ì£¼ì¥ 3"],
  "evidence": ["ì£¼ì¥ 1ì— ëŒ€í•œ ê·¼ê±°(ìˆ˜ì¹˜/íŒ©íŠ¸)", "ì£¼ì¥ 2ì— ëŒ€í•œ ê·¼ê±°", "ì£¼ì¥ 3ì— ëŒ€í•œ ê·¼ê±°"],
  "implications": "ì´ ë‚´ìš©ì´ ì£¼ëŠ” ì‹œì‚¬ì  ë° íˆ¬ì ì¸ì‚¬ì´íŠ¸ (ìƒì„¸ ê¸°ìˆ )",
  "validity_check": "ë…¼ë¦¬ì  íƒ€ë‹¹ì„± ë° ë¹„íŒì  ê²€í† ",
  "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
  "tags": "í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3",
  "full_summary": "ì „ì²´ ë‚´ìš© ìƒì„¸ ìš”ì•½ (ì„œë¡ -ë³¸ë¡ -ê²°ë¡ )"
}
"""

# ==========================================
# [í•µì‹¬ ë¡œì§]
# ==========================================

# 1. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
def connect_google_sheet():
    try:
        json_creds = json.loads(os.environ['GCP_CREDENTIALS_JSON'])
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_dict(json_creds, scope)
        client = gspread.authorize(creds)
        sheet = client.open("Youtube_Data_Store").sheet1 
        return sheet
    except Exception as e:
        print(f"ğŸš¨ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

# 2. ì´ë¯¸ ë¶„ì„í•œ ì˜ìƒ í™•ì¸
def get_existing_video_ids(sheet):
    try:
        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        if df.empty or 'ì˜ìƒID' not in df.columns:
            return []
        return df['ì˜ìƒID'].astype(str).tolist()
    except:
        return []

# 3. Gemini ë¶„ì„ ìš”ì²­
def analyze_video(video_url):
    try:
        api_key = os.environ['GOOGLE_API_KEY']
        genai.configure(api_key=api_key)
        # ëª¨ë¸ëª…ì€ ìƒí™©ì— ë”°ë¼ gemini-1.5-flash ë˜ëŠ” gemini-pro ì‚¬ìš©
        model = genai.GenerativeModel('gemini-2.5-flash') 
        
        full_prompt = f"{SYSTEM_PROMPT}\n\n[ë¶„ì„í•  ì˜ìƒ ë§í¬]: {video_url}"
        response = model.generate_content(full_prompt)
        
        text = response.text
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]
            
        return json.loads(text)
    except Exception as e:
        print(f"âŒ Gemini ë¶„ì„ ì‹¤íŒ¨ ({video_url}): {e}")
        return None

# 4. ë‚ ì§œ í•„í„°ë§ í•¨ìˆ˜ (í•µì‹¬ ì¶”ê°€!)
def is_recent_video(entry):
    try:
        # RSS í”¼ë“œì˜ ë‚ ì§œ íŒŒì‹± (struct_time)
        published_time = entry.published_parsed
        # datetime ê°ì²´ë¡œ ë³€í™˜
        video_date = datetime.fromtimestamp(mktime(published_time))
        # í˜„ì¬ ì‹œê°„ê³¼ì˜ ì°¨ì´ ê³„ì‚°
        delta = datetime.now() - video_date
        
        if delta.days <= FILTER_DAYS:
            return True, video_date.strftime("%Y-%m-%d")
        else:
            return False, video_date.strftime("%Y-%m-%d")
    except:
        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë‹¨ í†µê³¼ (í˜¹ì€ ìŠ¤í‚µ)
        return True, datetime.now().strftime("%Y-%m-%d")

# 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run_bot():
    print(f"ğŸš€ ë´‡ ì‹¤í–‰ ì‹œì‘: {datetime.now()}")
    
    sheet = connect_google_sheet()
    if not sheet: return

    existing_ids = get_existing_video_ids(sheet)
    print(f"ğŸ“š ê¸°ì¡´ ë°ì´í„° {len(existing_ids)}ê°œ ë¡œë“œ ì™„ë£Œ")

    new_videos_found = 0

    for channel_name, channel_id in TARGET_CHANNELS.items():
        rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
        feed = feedparser.parse(rss_url)
        
        print(f"ğŸ“¡ ì±„ë„ ìŠ¤ìº” ì¤‘: {channel_name}")
        
        for entry in feed.entries:
            video_id = entry.yt_videoid
            video_url = entry.link
            video_title = entry.title
            
            # [1] ì´ë¯¸ DBì— ìˆìœ¼ë©´ ìŠ¤í‚µ
            if video_id in existing_ids:
                continue 

            # [2] ë‚ ì§œ í•„í„°ë§ (ì˜¤ë˜ëœ ì˜ìƒ ìŠ¤í‚µ)
            is_recent, video_date = is_recent_video(entry)
            if not is_recent:
                # print(f"   PASS: ë„ˆë¬´ ì˜¤ë˜ëœ ì˜ìƒ ({video_date}) - {video_title}")
                continue

            print(f"   âœ¨ ì‹ ê·œ ì˜ìƒ ë°œê²¬! ({video_date}) ë¶„ì„ ì‹œì‘... [{video_title}]")
            
            # Geminiì—ê²Œ ë¶„ì„ ìš”ì²­
            result = analyze_video(video_url)
            
            if result:
                key_args = "\n- ".join(result.get("key_arguments", []))
                if key_args: key_args = "- " + key_args
                
                evidence = "\n- ".join(result.get("evidence", []))
                if evidence: evidence = "- " + evidence

                row_data = [
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    result.get("published_at", video_date), # Geminiê°€ ë‚ ì§œ ëª» ì°¾ìœ¼ë©´ RSS ë‚ ì§œ ì‚¬ìš©
                    result.get("video_id", video_id),
                    result.get("title", video_title),
                    result.get("channel_name", channel_name),
                    result.get("main_topic", ""),
                    key_args,
                    evidence,
                    result.get("implications", ""),
                    result.get("validity_check", ""),
                    result.get("sentiment", ""),
                    result.get("full_summary", ""),
                    result.get("tags", ""),
                    result.get("url", video_url)
                ]
                
                sheet.append_row(row_data)
                print(f"   âœ… ì €ì¥ ì™„ë£Œ!")
                existing_ids.append(video_id)
                new_videos_found += 1
                time.sleep(5) # API ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€ê¸° ì‹œê°„ ëŠ˜ë¦¼

    print(f"ğŸ ì‘ì—… ì¢…ë£Œ. ì´ {new_videos_found}ê°œì˜ ìƒˆ ì˜ìƒì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_bot()
